{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGUATHON ITA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on:\n",
    "\n",
    "## Machine Learning Mastery With Python\n",
    "### End-to-End Project\n",
    "#### Based on: Jason Brownlee Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.1.0 \n",
      "numpy: 1.15.4 \n",
      "matplotlib: 3.0.2 \n",
      "pandas: 0.23.4 \n",
      "sklearn: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "print( 'scipy: {} ' .format(scipy.__version__))\n",
    "print( 'numpy: {} ' .format(np.__version__))\n",
    "print( 'matplotlib: {} ' .format(mpl.__version__))\n",
    "print( 'pandas: {} ' .format(pd.__version__))\n",
    "print('sklearn: {}' .format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    ''' \n",
    "    Load CSV using Pandas saved in current working directory\n",
    "    '''\n",
    "    cwd = os.getcwd()\n",
    "    in_path = os.path.join(cwd,'data','ENTRADA')\n",
    "    in_file = 'datos.csv'\n",
    "    filename  = os.path.join(in_path,in_file)\n",
    "    #names = [ 'preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class' ]\n",
    "                #df = pd.read_csv(in_csv\n",
    "                #             , parse_dates=[['date','time']]\n",
    "                #             , infer_datetime_format=True\n",
    "                #             , index_col='date_time')\n",
    "    data = pd.read_csv(filename, parse_dates = ['time']) #, names=names)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tud</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Ala</th>\n",
       "      <th>Zar</th>\n",
       "      <th>Gri</th>\n",
       "      <th>Tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>1.6000</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.6075</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.2650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tud     Nov     Ala   Zar     Gri     Tau\n",
       "0  0.7875  1.6000  0.8100  0.74  0.4375  0.2675\n",
       "1  0.7900  1.6075  0.8100  0.74  0.4725  0.2650\n",
       "2  0.7900  1.6100  0.8100  0.74  0.5425  0.2675\n",
       "3  0.7900  1.6100  0.8075  0.74  0.5500  0.2600\n",
       "4  0.7900  1.6025  0.8000  0.74  0.5525  0.2650"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_dataset()\n",
    "data.columns = ['time','Ala','Gri','Nov','Tau','Tud','Zar','Risk','P24','P48','P72']\n",
    "cols = [x for x in data.columns if x !='Risk']\n",
    "df = data.loc[:,cols]\n",
    "\n",
    "### FILL MISSING VALUES\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "Y = df['P24']\n",
    "X = df.loc[:,('Tud', 'Nov', 'Ala', 'Zar', 'Gri', 'Tau')]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = (df).copy()\n",
    "dfplot.set_index('time', drop=True, inplace=True)\n",
    "dfplot = dfplot/8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = dt.datetime(2017,1,1)\n",
    "time2 = dt.datetime(2017,12,31)\n",
    "f1 = time1 <= dfplot.index\n",
    "f2 = time2 >= dfplot.index\n",
    "f3 = f1&f2\n",
    "\n",
    "#['time','Ala','Gri','Nov','Tau','Tud','Zar','Risk','P24','P48','P72']\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, \n",
    "                                               sharey=False,\n",
    "                                               figsize=(8,5))\n",
    "dfplot.loc[f3,'Tud'].plot( ax=ax1)\n",
    "dfplot.loc[f3,'Nov'].plot( ax=ax2)\n",
    "dfplot.loc[f3,'Ala'].plot( ax=ax3)\n",
    "dfplot.loc[f3,'Zar'].plot( ax=ax4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peek = data.head(20)\n",
    "#print(peek)\n",
    "shape = data.shape\n",
    "print(shape)\n",
    "types = data.dtypes\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will note some calls to pandas.set option() in the recipe to \n",
    "# change the precision of the numbers and the preferred width of the output\n",
    "\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('precision', 2)\n",
    "description = data.describe()\n",
    "#print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Balance\n",
    "On classiﬁcation problems you need to know how balanced the class values are. Highly imbalanced\n",
    "problems (a lot more observations for one class than another) are common and may need special\n",
    "handling in the data preparation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data.groupby('Risk').size()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations Between Attributes\n",
    "Correlation refers to the relationship between two variables and how they may or may not\n",
    "change together. The most common method for calculating correlation is Pearson’s Correlation\n",
    "Coeﬃcient, that assumes a normal distribution of the attributes involved. A correlation of -1\n",
    "or 1 shows a full negative or positive correlation respectively. Whereas a value of 0 shows no\n",
    "correlation at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise Pearson correlations\n",
    "correlations = data.corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness of Univariate Distributions\n",
    "Skew refers to a distribution that is assumed Gaussian (normal or bell curve) that is shifted or\n",
    "squashed in one direction or another. Many machine learning algorithms assume a Gaussian\n",
    "distribution. Knowing that an attribute has a skew may allow you to perform data preparation\n",
    "to correct the skew and later improve the accuracy of your models. The skew result show a positive (right) or negative (left) skew. Values closer to zero show\n",
    "less skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = data.skew()\n",
    "print(skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Histograms\n",
    "A fast way to get an idea of the distribution of each attribute is to look at histograms. Histograms\n",
    "group data into bins and provide you a count of the number of observations in each bin. From\n",
    "the shape of the bins you can quickly get a feeling for whether an attribute is Gaussian, skewed\n",
    "or even has an exponential distribution. It can also help you see possible outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Histograms\n",
    "df.hist(bins=20, figsize  = [10, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Density Plots\n",
    "Density plots are another way of getting a quick idea of the distribution of each attribute. The\n",
    "plots look like an abstracted histogram with a smooth curve drawn through the top of each bin,\n",
    "much like your eye tried to do with the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind= 'density' , subplots=True, layout=(3,3), sharex=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Box and Whisker Plots\n",
    "Another useful way to review the distribution of each attribute is to use Box and Whisker Plots\n",
    "or boxplots for short. Boxplots summarize the distribution of each attribute, drawing a line for\n",
    "the median (middle value) and a box around the 25th and 75th percentiles (the middle 50% of\n",
    "the data). The whiskers give an idea of the spread of the data and dots outside of the whiskers\n",
    "show candidate outlier values (values that are 1.5 times greater than the size of spread of the\n",
    "middle 50% of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind= 'box' , subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Multivariate Plots\n",
    "Plots that show the interactions between multiple variables in your dataset.\n",
    "* Correlation Matrix Plot.\n",
    "* Scatter Plot Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corr()\n",
    "# plot correlation matrix\n",
    "names=df.columns\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kw = {'axes.edgecolor': '0', 'text.color': '0', 'ytick.color': '0', 'xtick.color': '0',\n",
    "#      'ytick.major.size': 2, 'xtick.major.size': 2, 'axes.labelcolor': '0'}\n",
    "\n",
    "#sns.set_style(\"whitegrid\", kw)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 11))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, n=10, as_cmap=True)\n",
    "#cmap = sns.diverging_palette(220, 10, n=10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0.5, vmin=0, vmax=1,\n",
    "            square=True, linewidths=.2, cbar_kws={\"shrink\": .6})\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    # label is a Text instance\n",
    "    label.set_rotation(90)\n",
    "    label.set_fontsize(8)\n",
    "for label in ax.yaxis.get_ticklabels():\n",
    "    # label is a Text instance\n",
    "    label.set_rotation(0)\n",
    "    label.set_fontsize(8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Scatter Plot Matrix\n",
    "A scatter plot shows the relationship between two variables as dots in two dimensions, one\n",
    "axis for each attribute. You can create a scatter plot for each pair of attributes in your data.\n",
    "Drawing all these scatter plots together is called a scatter plot matrix. Scatter plots are useful\n",
    "for spotting structured relationships between variables, like whether you could summarize the\n",
    "relationship between two variables with a line. Attributes with structured relationships may\n",
    "also be correlated and good candidates for removal from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix = pd.plotting.scatter_matrix(\n",
    "    df,\n",
    "    figsize  = [15, 10],\n",
    "    marker   = \".\",\n",
    "    s        = 0.2,)\n",
    "\n",
    "for ax in scatter_matrix.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize = 10, rotation = 0)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize = 10, rotation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Prepare  Data For Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rescale Data\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms\n",
    "can beneﬁt from rescaling the attributes to all have the same scale. Often this is referred to\n",
    "as normalization and attributes are often rescaled into the range between 0 and 1. This is\n",
    "useful for optimization algorithms used in the core of machine learning algorithms like gradient\n",
    "descent. It is also useful for algorithms that weight inputs like regression and neural networks\n",
    "and algorithms that use distance measures like k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data (between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print(rescaledX[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Standardize Data\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and\n",
    "diﬀering means and standard deviations to a standard Gaussian distribution with a mean of\n",
    "0 and a standard deviation of 1. It is most suitable for techniques that assume a Gaussian\n",
    "distribution in the input variables and work better with rescaled data, such as linear regression,\n",
    "logistic regression and linear discriminate analysis. You can standardize data using scikit-learn\n",
    "with the StandardScaler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print(rescaledX[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Normalize Data\n",
    "Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called\n",
    "a unit norm or a vector with the length of 1 in linear algebra). This pre-processing method\n",
    "can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using\n",
    "algorithms that weight input values such as neural networks and algorithms that use distance\n",
    "measures such as k-Nearest Neighbors. You can normalize data in Python with scikit-learn\n",
    "using the Normalizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=2)\n",
    "print(normalizedX[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Binarize Data (Make Binary)\n",
    "You can transform your data using a binary threshold. All values above the threshold are\n",
    "marked 1 and all equal to or below are marked as 0. This is called binarizing your data or\n",
    "thresholding your data. It can be useful when you have probabilities that you want to make crisp\n",
    "values. It is also useful when feature engineering and you want to add new features that indicate\n",
    "something meaningful. You can create new binary attributes in Python using scikit-learn with\n",
    "the Binarizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=2)\n",
    "print(X[0:10,:])\n",
    "print(binaryX[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Feature Selection For Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data features that you use to train your machine learning models have a huge inﬂuence on\n",
    "the performance you can achieve. Irrelevant or partially relevant features can negatively impact\n",
    "model performance. Feature selection is a process where you automatically select those features in your data that\n",
    "contribute most to the prediction variable or output in which you are interested. Having\n",
    "irrelevant features in your data can decrease the accuracy of many models, especially linear\n",
    "algorithms like linear and logistic regression. Three beneﬁts of performing feature selection\n",
    "before modeling your data are:\n",
    "\n",
    "* Reduces Overﬁtting: Less redundant data means less opportunity to make decisions\n",
    "based on noise.\n",
    "* Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "* Reduces Training Time: Less data means that algorithms train faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with\n",
    "the output variable. The scikit-learn library provides the SelectKBest class 2 that can be used\n",
    "with a suite of diﬀerent statistical tests to select a speciﬁc number of features. The example\n",
    "below uses the chi-squared (chi 2 ) statistical test for non-negative features to select 4 of the best\n",
    "features from the  dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and\n",
    "building a model on those attributes that remain. It uses the model accuracy to identify which attributes \n",
    "(and combination of attributes) contribute the most to predicting the target attribute.\n",
    "The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of\n",
    "algorithm does not matter too much as long as it is skillful and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [ True  True False  True False False]\n",
      "Feature Ranking: [1 1 4 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: {}\".format(fit.n_features_))\n",
    "print(\"Selected Features: {}\".format(fit.support_))\n",
    "print(\"Feature Ranking: {}\".format(fit.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Principal Component Analysis\n",
    "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a\n",
    "compressed form. Generally this is called a data reduction technique. A property of PCA is that\n",
    "you can choose the number of dimensions or principal components in the transformed result. In\n",
    "the example below, we use PCA and select 3 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load data\n",
    "#X, Y =load_pima_dataset()\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# summarize components\n",
    "print(\"Explained Variance: {}\".format(fit.explained_variance_ratio_))\n",
    "print(fit.components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Importance\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
    "of features. In the example below we construct a ExtraTreesClassifier classiﬁer for the Pima\n",
    "Indians onset of diabetes dataset. You can see that we are given an importance score for each attribute where the larger the score, the more important the attribute. The scores suggest at the importance of plas, age\n",
    "and mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Evaluate the Performance of Machine Learning Algorithms with Resampling\n",
    "\n",
    "You need to know how well your algorithms perform on unseen data. The best way to evaluate\n",
    "the performance of an algorithm would be to make predictions for new data to which you\n",
    "already know the answers. The second best way is to use clever techniques from statistics called\n",
    "resampling methods that allow you to make accurate estimates for how well your algorithm will\n",
    "perform on new data. In this chapter you will discover how you can estimate the accuracy of\n",
    "your machine learning algorithms using resampling methods in Python.\n",
    "\n",
    "We must evaluate our machine learning algorithms on\n",
    "data that is not used to train the algorithm.\n",
    "The evaluation is an estimate that we can use to talk about how well we think the algorithm\n",
    "may actually do in practice. It is not a guarantee of performance. Once we estimate the\n",
    "performance of our algorithm, we can then re-train the ﬁnal algorithm on the entire training\n",
    "dataset and get it ready for operational use. Next up we are going to look at four diﬀerent\n",
    "techniques that we can use to split up our training dataset and create useful estimates of\n",
    "performance for our machine learning algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Split into Train and Test Sets\n",
    "The simplest method that we can use to evaluate the performance of a machine learning\n",
    "algorithm is to use diﬀerent training and testing datasets. We can take our original dataset and\n",
    "split it into two parts. Train the algorithm on the ﬁrst part, make predictions on the second\n",
    "part and evaluate the predictions against the expected results. The size of the split can depend\n",
    "on the size and speciﬁcs of your dataset, although it is common to use 67% of the data for\n",
    "training and the remaining 33% for testing.\n",
    "This algorithm evaluation technique is very fast. It is ideal for large datasets (millions of\n",
    "records) where there is strong evidence that both splits of the data are representative of the\n",
    "underlying problem. Because of the speed, it is useful to use this approach when the algorithm\n",
    "you are investigating is slow to train. A downside of this technique is that it can have a high\n",
    "variance. This means that diﬀerences in the training and test dataset can result in meaningful\n",
    "diﬀerences in the estimate of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.571\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "result = model.score(X_test, Y_test)\n",
    "print('Accuracy: {:.3f}'.format( result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the estimated accuracy for the model was approximately 75%. Note that\n",
    "in addition to specifying the size of the split, we also specify the random seed. Because the\n",
    "split of the data is random, we want to ensure that the results are reproducible. By specifying\n",
    "the random seed we ensure that we get the same random numbers each time we run the code\n",
    "and in turn the same split of data. This is important if we want to compare this result to\n",
    "the estimated accuracy of another machine learning algorithm or the same algorithm with a\n",
    "diﬀerent conﬁguration. **To ensure the comparison was apples-for-apples, we must ensure that\n",
    "they are trained and tested on exactly the same data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 K-fold Cross Validation\n",
    "Cross validation is an approach that you can use to estimate the performance of a machine\n",
    "learning algorithm with less variance than a single train-test set split. It works by splitting\n",
    "the dataset into k-parts (e.g. k = 5 or k = 10). Each split of the data is called a fold. The\n",
    "algorithm is trained on k − 1 folds with one held back and tested on the held back fold. This is\n",
    "repeated so that each fold of the dataset is given a chance to be the held back test set. After\n",
    "running cross validation you end up with k diﬀerent performance scores that you can summarize\n",
    "using a mean and a standard deviation.\n",
    "The result is a more reliable estimate of the performance of the algorithm on new data. It is\n",
    "more accurate because the algorithm is trained and evaluated multiple times on diﬀerent data.\n",
    "The choice of k must allow the size of each test partition to be large enough to be a reasonable\n",
    "sample of the problem, whilst allowing enough repetitions of the train-test evaluation of the\n",
    "algorithm to provide a fair estimate of the algorithms performance on unseen data. For modest\n",
    "sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are\n",
    "common. In the example below we use 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.789% (1.234%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "num_folds = 5\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: {:.3f}% ({:.3f}%)\".format(results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Leave One Out Cross Validation\n",
    "You can conﬁgure cross validation so that the size of the fold is 1 (k is set to the number of\n",
    "observations in your dataset). This variation of cross validation is called leave-one-out cross\n",
    "validation. The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data.\n",
    "A downside is that it can be a computationally more expensive procedure than k-fold cross\n",
    "validation. In the example below we use leave-one-out cross validation. You can see in the resulting standard deviation that the score has more variance than the k-fold cross\n",
    "validation results described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load data\n",
    "num_folds = 5\n",
    "loocv = LeaveOneOut()\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print('Accuracy: {:.3f}% ({:.3f}%)'.format( results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Repeated Random Test-Train Splits\n",
    "Another variation on k-fold cross validation is to create a random split of the data like the\n",
    "train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, \n",
    "like cross validation. This has the speed of using a train/test split and the reduction in variance in the estimated \n",
    "performance of k-fold cross validation. You can also repeat the process many more times as needed to improve the accuracy. \n",
    "A down side is that repetitions may include much of the same data in the train or the test split from run to run, \n",
    "introducing redundancy into the evaluation. The example below splits the data into a 67%/33% train/test split and repeats \n",
    "the process 10 times. We can see that in this case the distribution of the performance measure is on par with\n",
    "k-fold cross validation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.600% (0.020%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# load data\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: {:.3f}% ({:.3f}%)\".format( results.mean()*100.0, results.std()*100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 What Techniques to Use When\n",
    "This section lists some tips to consider what resampling technique to use in different circumstances. Generally k-fold cross validation is the gold standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10. Using a train/test split is good for speed when using a slow algorithm and produces\n",
    "performance estimates with lower bias when using large datasets.\n",
    "Techniques like leave-one-out cross validation and repeated random splits can be useful\n",
    "intermediates when trying to balance variance in the estimated performance, model\n",
    "training speed and dataset size. The best advice is to experiment and ﬁnd a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "\n",
    "### 6.1 Classiﬁcation Metrics\n",
    "Classiﬁcation problems are perhaps the most common type of machine learning problem and as such there are a myriad of metrics that can be used to evaluate predictions for these problems. In this section we will review how to use the following metrics:\n",
    "* Classiﬁcation Accuracy.\n",
    "* Logarithmic Loss.\n",
    "* Area Under ROC Curve.\n",
    "* Confusion Matrix.\n",
    "* Classiﬁcation Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Regression Metrics\n",
    "In this section will review 3 of the most common metrics for evaluating predictions on regression machine learning problems:\n",
    "* Mean Absolute Error.\n",
    "* Mean Squared Error.\n",
    "* R2 \n",
    "\n",
    "#### Mean Absolute Error\n",
    "The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions and actual values. \n",
    "It gives an idea of how wrong the predictions were. The measure gives an idea of the magnitude of the error, \n",
    "but no idea of the direction (e.g. over or under predicting. The example below demonstrates calculating mean absolute \n",
    "error on the Boston house price dataset. A value of 0 indicates no error or perfect predictions. Like logloss, this metric \n",
    "is inverted by the cross val score() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.064 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MAE\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print('MAE: {:.3f} ({:.3f})'.format( results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error\n",
    "The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a\n",
    "gross idea of the magnitude of error. Taking the square root of the mean squared error converts \n",
    "the units back to the original units of the output variable and can be meaningful for description and presentation. \n",
    "This is called the Root Mean Squared Error (or RMSE). This metric too is inverted so that the results are increasing. \n",
    "Remember to take the absolute value before taking the square root if you are interested in calculating the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.008 (0.003)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print('MSE: {:.3f} ({:.3f})'.format( results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R<sup>2</sup> Metric\n",
    "The R<sup>2</sup> (or R Squared) metric provides an indication of the goodness of ﬁt of a set of predictions to the actual values. \n",
    "In statistical literature this measure is called the coeffcient of determination. This is a value between 0 and 1 for \n",
    "no-ﬁt and perfect ﬁt respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.975 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression R^2\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print('R2: {:.3f} ({:.3f})'.format( results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Regression Algorithms\n",
    "Spot checking is a way of discovering which algorithms perform well on your machine learning problem. \n",
    "You cannot know which algorithms are best suited to your problem beforehand. You must trial a number of methods and \n",
    "focus attention on those that prove themselves the most promising.\n",
    "\n",
    " Starting with four linear machine learning algorithms:\n",
    "\n",
    "* Linear Regression.\n",
    "* Ridge Regression.\n",
    "* LASSO Linear Regression.\n",
    "* Elastic Net Regression.\n",
    "\n",
    "Then looking at three nonlinear machine learning algorithms:\n",
    "\n",
    "* k-Nearest Neighbors.\n",
    "* Classiﬁcation and Regression Trees.\n",
    "* Support Vector Machines.\n",
    "\n",
    "Each recipe is demonstrated on the Boston House Price dataset. This is a regression\n",
    "problem where all attributes are numeric. A test harness with 10-fold cross validation is used\n",
    "to demonstrate how to spot-check each machine learning algorithm and mean squared error\n",
    "measures are used to indicate algorithm performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Linear Regression\n",
    "Linear regression assumes that the input variables have a Gaussian distribution. It is also\n",
    "assumed that input variables are relevant to the output variable and that they are not highly\n",
    "correlated with each other (a problem called collinearity).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750457777887982\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Ridge Regression\n",
    "Ridge regression is an extension of linear regression where the loss function is modiﬁed to minimize the \n",
    "complexity of the model measured as the sum squared value of the coefficient values (also called the L2-norm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975042058913286\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Ridge()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 LASSO Regression\n",
    "The Least Absolute Shrinkage and Selection Operator (or LASSO for short) is a modiﬁcation of linear regression, like \n",
    "ridge regression, where the loss function is modiﬁed to minimize the complexity of the model measured as the sum absolute \n",
    "value of the coeﬃcient values (also called the L1-norm). You can construct a LASSO model by using the Lasso class 3 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2642311581455731\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Lasso()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 ElasticNet Regression\n",
    "ElasticNet is a form of regularization regression that combines the properties of both Ridge Regression and LASSO \n",
    "regression. It seeks to minimize the complexity of the regression model (magnitude and number of regression coeffcients) \n",
    "by penalizing the model using both the L2-norm (sum squared coeffcient values) and the L1-norm \n",
    "(sum absolute coeffcient values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46842514946746616\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = ElasticNet()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Machine Learning Algorithms\n",
    "\n",
    "### 8.5 K-Nearest Neighbors\n",
    "The k-Nearest Neighbors algorithm (or KNN) locates the k most similar instances in the\n",
    "training dataset for a new data instance. From the k neighbors, a mean or median output\n",
    "variable is taken as the prediction. Of note is the distance metric used (the metric argument). \n",
    "The Minkowski distance is used by default, which is a generalization of both the Euclidean\n",
    "distance (used when all inputs have the same scale) and Manhattan distance (for when the\n",
    "scales of the input variables differ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9578451881013061\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsRegressor()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Classiﬁcation and Regression Trees\n",
    "Decision trees or the Classiﬁcation and Regression Trees (CART as they are known) use the training data to select the \n",
    "best points to split the data in order to minimize a cost metric. The default cost metric for regression decision trees \n",
    "is the mean squared error, speciﬁed in the criterion parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9684205068119078\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeRegressor()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8.7 Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841246707766766\n"
     ]
    }
   ],
   "source": [
    "# GB Regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#num_folds = 2\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GradientBoostingRegressor(n_estimators=100, \n",
    "                                learning_rate=0.1, \n",
    "                                max_depth=7, \n",
    "                                random_state=0, \n",
    "                                loss='ls')\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Compare Machine Learning Algorithms\n",
    "It is important to compare the performance of multiple diﬀerent machine learning algorithms consistently. \n",
    "In this chapter you will discover how you can create a test harness to compare multiple different machine learning \n",
    "algorithms in Python with scikit-learn. You can use this test harness as a template on your own machine learning problems \n",
    "and add more and different algorithms to compare.\n",
    "\n",
    "The key to a fair comparison of machine learning algorithms is ensuring that each algorithm is\n",
    "evaluated in the same way on the same data. You can achieve this by forcing each algorithm to be evaluated on a consistent test harness.\n",
    "\n",
    "In the example below six diﬀerent classiﬁcation\n",
    "algorithms are compared on a single dataset: The problem has two classes and\n",
    "eight numeric input variables of varying scales. The 10-fold cross validation procedure is used to\n",
    "evaluate each algorithm, importantly conﬁgured with the same random seed to ensure that the\n",
    "same splits to the training data are performed and that each algorithm is evaluated in precisely\n",
    "the same way. Each algorithm is given a short name, useful for summarizing results afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINR: 0.9750457777887982 (0.015868856037480606)\n",
      "RDGE: 0.975042058913286 (0.015871207087194267)\n",
      "LASS: -0.2642311581455731 (0.46316288309503434)\n",
      "ELAN: 0.46842514946746616 (0.18165119820377487)\n",
      "KNB: 0.9578451881013061 (0.040987711255285664)\n",
      "DTR: 0.9681913744359065 (0.01741348241074636)\n",
      "GBR: 0.984917085572472 (0.007605834136652539)\n"
     ]
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(( 'LINR' , LinearRegression()))\n",
    "models.append(( 'RDGE' , Ridge()))\n",
    "models.append(( 'LASS' , Lasso()))\n",
    "models.append(( 'ELAN' , ElasticNet()))\n",
    "models.append(( 'KNB' , KNeighborsRegressor()))\n",
    "models.append(( 'DTR' , DecisionTreeRegressor()))\n",
    "models.append(( 'GBR' , GradientBoostingRegressor()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'r2'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '{}: {} ({})'.format(name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10 Automate Machine Learning Workﬂows with Pipelines\n",
    "\n",
    "There are standard workﬂows in a machine learning project that can be automated. Pipelines work by allowing for a linear\n",
    "sequence of data transforms to be chained together culminating in a modeling process that can\n",
    "be evaluated. The goal is to ensure that all of the steps in the pipeline are constrained to the data available\n",
    "for the evaluation, such as the training dataset or each fold of the cross validation procedure.\n",
    "\n",
    "### 10.1 Data Preparation and Modeling Pipeline\n",
    "\n",
    "An easy trap to fall into in applied machine learning is leaking data from your training dataset\n",
    "to your test dataset. To avoid this trap you need a robust test harness with strong separation of training and testing. \n",
    "This includes data preparation. Data preparation is one easy way to leak knowledge of the whole training dataset \n",
    "to the algorithm. For example, preparing your data using normalization or standardization on the entire training \n",
    "dataset before learning would not be a valid test because the training dataset would have been inﬂuenced by the scale \n",
    "of the data in the test set.\n",
    "\n",
    "Pipelines help you prevent data leakage in your test harness by ensuring that data preparation\n",
    "like standardization is constrained to each fold of your cross validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750457777887984\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(( 'standardize' , StandardScaler()))\n",
    "estimators.append(( 'LRE' , LinearRegression()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Feature Extraction and Modeling Pipeline\n",
    "\n",
    "Feature extraction is another procedure that is susceptible to data leakage. Like data preparation,\n",
    "feature extraction procedures must be restricted to the data in your training dataset. The\n",
    "pipeline provides a handy tool called the FeatureUnion which allows the results of multiple\n",
    "feature selection and extraction procedures to be combined into a larger dataset on which a\n",
    "model can be trained. Importantly, all the feature extraction and the feature union occurs\n",
    "within each fold of the cross validation procedure.\n",
    "\n",
    "The example below demonstrates the pipeline  deﬁned with four steps:\n",
    "1. Feature Extraction with Principal Component Analysis (3 features).\n",
    "2. Feature Extraction with Statistical Selection (6 features).\n",
    "3. Feature Union.\n",
    "4. Learn a Logistic Regression Model.\n",
    "\n",
    "The pipeline is then evaluated using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that extracts features from the data then creates a model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# load data\n",
    "\n",
    "\n",
    "# create feature union\n",
    "features = []\n",
    "features.append(( 'pca' , PCA(n_components=3)))\n",
    "features.append(( 'select_best' , SelectKBest(k=6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(( 'feature_union' , feature_union))\n",
    "estimators.append(( 'logistic' , LogisticRegression()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 11 Improve Performance with Ensembles\n",
    "\n",
    "\n",
    "### Combine Models Into Ensemble Predictions\n",
    "\n",
    "Ensembles can give you a boost in accuracy on your dataset. The three most popular methods for combining the predictions from diﬀerent models are:\n",
    "* Bagging. Building multiple models (typically of the same type) from diﬀerent subsamples of the training dataset.\n",
    "* Boosting. Building multiple models (typically of the same type) each of which learns to ﬁx the prediction errors of a prior model in the sequence of models.\n",
    "* Voting. Building multiple models (typically of diﬀering types) and simple statistics (like calculating the mean) are used to combine predictions.\n",
    "\n",
    "### 11.1 Bagging Algorithms\n",
    "Bootstrap Aggregation (or Bagging) involves taking multiple samples from your training dataset\n",
    "(with replacement) and training a model for each sample. The ﬁnal output prediction is averaged\n",
    "across the predictions of all of the sub-models. The three bagging models covered in this section\n",
    "are as follows:\n",
    "* Bagged Decision Trees.\n",
    "* Random Forest.\n",
    "* Extra Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagged Decision Trees\n",
    "Bagging performs best with algorithms that have high variance. A popular example are\n",
    "decision trees, often constructed without pruning. In the example below is an example\n",
    "of using the BaggingClassifier with the Classiﬁcation and Regression Trees algorithm.\n",
    "A total of 100 trees are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegresor\n",
    "\n",
    "# load data\n",
    "\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "cart = DecisionTreeRegressor()\n",
    "num_trees = 100\n",
    "model = BaggingRegressor(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "Random Forests is an extension of bagged decision trees. Samples of the training dataset are\n",
    "taken with replacement, but the trees are constructed in a way that reduces the correlation\n",
    "between individual classiﬁers. Speciﬁcally, rather than greedily choosing the best split point in\n",
    "the construction of each tree, only a random subset of features are considered for each split. \n",
    "The example below demonstrates using Random Forest for classiﬁcation with 100 trees\n",
    "and split points chosen from a random selection of 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838906613383192\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# load data\n",
    "\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = RandomForestRegressor(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees\n",
    "Extra Trees are another modiﬁcation of bagging where random trees are constructed from\n",
    "samples of the training dataset. You can construct an Extra Trees model for classiﬁcation using\n",
    "the ExtraTreesClassifier class 3 . The example below provides a demonstration of extra trees\n",
    "with the number of trees set to 100 and splits chosen from 7 random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9813715778691032\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# load data\n",
    "\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = ExtraTreesRegressor(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Boosting Algorithms\n",
    "Boosting ensemble algorithms creates a sequence of models that attempt to correct the mistakes\n",
    "of the models before them in the sequence. Once created, the models make predictions which\n",
    "may be weighted by their demonstrated accuracy and the results are combined to create a ﬁnal\n",
    "output prediction. The two most common boosting ensemble machine learning algorithms are:\n",
    "* AdaBoost.\n",
    "* Stochastic Gradient Boosting.\n",
    "\n",
    "#### AdaBoost\n",
    "AdaBoost was perhaps the ﬁrst successful boosting ensemble algorithm. It generally works\n",
    "by weighting instances in the dataset by how easy or diﬃcult they are to classify, allowing\n",
    "the algorithm to pay or less attention to them in the construction of subsequent models. The\n",
    "example below demonstrates the construction of 30 decision trees in sequence using the AdaBoost\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942511771179479\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Regressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# load data\n",
    "\n",
    "num_trees = 30\n",
    "seed=7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostRegressor(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Performance with Algorithm Tuning\n",
    "\n",
    "Algorithm tuning is a ﬁnal step in the process of applied machine learning before ﬁnalizing your\n",
    "model. It is sometimes called hyperparameter optimization where the algorithm parameters\n",
    "are referred to as hyperparameters, whereas the coeﬃcients found by the machine learning\n",
    "algorithm itself are referred to as parameters. Optimization suggests the search-nature of the\n",
    "problem. Phrased as a search problem, you can use diﬀerent search strategies to ﬁnd a good and\n",
    "robust parameter or set of parameters for an algorithm on a given problem.\n",
    "\n",
    "####  Grid Search Parameter Tuning\n",
    "Grid search is an approach to parameter tuning that will methodically build and evaluate a\n",
    "model for each combination of algorithm parameters speciﬁed in a grid. You can perform a grid\n",
    "search using the GridSearchCV class 1 . The example below evaluates diﬀerent alpha values for\n",
    "the Ridge Regression algorithm on the standard diabetes dataset. This is a one-dimensional\n",
    "grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Algorithm Tuning\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load data\n",
    "#X, Y = load_pima_dataset()\n",
    "\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "param_grid = dict(alpha=alphas)\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(X, Y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Parameter Tuning\n",
    "Random search is an approach to parameter tuning that will sample algorithm parameters from\n",
    "a random distribution (i.e. uniform) for a ﬁxed number of iterations. A model is constructed\n",
    "and evaluated for each combination of parameters chosen. The example below evaluates\n",
    "diﬀerent random alpha values between 0 and 1 for the Ridge Regression algorithm on the\n",
    "standard diabetes dataset. A total of 100 iterations are performed with uniformly random alpha\n",
    "values selected in the range between 0 and 1 (the range that alpha values can take)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized for Algorithm Tuning\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# load data\n",
    "#X, Y = load_pima_dataset()\n",
    "\n",
    "param_grid = { 'alpha' : uniform()}\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, random_state=7)\n",
    "rsearch.fit(X, Y)\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Machine Learning Models\n",
    "\n",
    "#### Finalize Your Model with pickle\n",
    "Pickle is the standard way of serializing objects in Python. \n",
    "to serialize your machine learning algorithms and save the serialized format to a ﬁle. Later you\n",
    "can load this ﬁle to deserialize your model and use it to make new predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "# load data\n",
    "#X, Y = load_pima_dataset()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# Fit the model on 33%\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "dump(model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = load(open(filename, 'rb' ))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize Your Model with Joblib\n",
    "The Joblib library is part of the SciPy ecosystem and provides utilities for pipelining Python\n",
    "jobs. It provides utilities for saving and loading Python objects that make use of NumPy data\n",
    "structures, eﬃciently 3 . This can be useful for some machine learning algorithms that require a\n",
    "lot of parameters or store the entire dataset (e.g. k-Nearest Neighbors). The example below\n",
    "demonstrates how you can train a logistic regression model on the Pima Indians onset of diabetes\n",
    "dataset, save the model to ﬁle using Joblib and load it to make predictions on the unseen test\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "\n",
    "# load data\n",
    "# X, Y = load_pima_dataset()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# Fit the model on 33%\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "dump(model, filename)\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Finalizing Your Model\n",
    "This section lists some important considerations when ﬁnalizing your machine learning models.\n",
    "\n",
    "* Python Version. Take note of the Python version. You almost certainly require the same major (and maybe minor) version of Python used to serialize the model when you later load it and deserialize it.\n",
    "\n",
    "* Library Versions. The version of all major libraries used in your machine learning project almost certainly need to be the same when deserializing a saved model. This is not limited to the version of NumPy and the version of scikit-learn.\n",
    "\n",
    "* Manual Serialization. You might like to manually output the parameters of your learned model so that you can use them directly in scikit-learn or another platform in the future. Often the techniques used internally by machine learning algorithms to make predictions are a lot simpler than those used to learn the parameters can may be easy to implement in custom code that you have control over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
